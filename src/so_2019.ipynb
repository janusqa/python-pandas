{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "cb948981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For notebook, use:\n",
    "ROOT_DIR = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e754dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 85)\n",
    "pd.set_option(\"display.max_rows\", 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075aa807",
   "metadata": {},
   "source": [
    "### DATAFRAMES AND SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b141bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv(ROOT_DIR / \"data\" / \"stackoverflow_survey\" / \"2019\" / \"survey_results_public.csv\")\n",
    "schema_df = pd.read_csv(ROOT_DIR / \"data\" / \"stackoverflow_survey\" / \"2019\" / \"survey_results_schema.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head takes an int to say how many rows to display.\n",
    "df.head() # first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() # last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display how many rows and columns make up the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays number of rows and columns in data, and additionally datatypes of the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48837aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column\n",
    "df[\"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiple columns\n",
    "df[[\"Hobbyist\", \"MainBranch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3fa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiple rows\n",
    "df.iloc[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first row but based on a lable.  By default if no lables are set they default to numeric range\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58035fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiple rows\n",
    "df.loc[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select row 1 and 2, but only display column 4\n",
    "df.iloc[[0,1],3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using loc now, so for colums need to use proper label for it and not an int\n",
    "df.loc[[0,1], [\"OpenSourcer\",\"OpenSource\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, \"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 3 responses for hobbiyst column\n",
    "df.loc[[0,1,2],\"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing\n",
    "# NOTE when slicing the end range is INCLUSIVE\n",
    "# 0:2 means from 0 to 2 (and not to 1 as in normal ranges)\n",
    "# NOTE no brackets needed around slicing\n",
    "df.loc[0:2, \"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing on the columns\n",
    "df.loc[0:2, \"Hobbyist\":\"Employment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd532d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a dict to a dataframe\n",
    "people = {\n",
    "    \"first\":[\"Corey\", \"Jane\", \"John\"],\n",
    "    \"last\": [\"Schafer\", \"Doe\", \"Doe\"],\n",
    "    \"email\": [\"CoreySchafer@email.com\",\"JaneDoe@email.com\",\"JohnDoe@email.com\"]\n",
    "}\n",
    "\n",
    "dict_df = pd.DataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cce185",
   "metadata": {},
   "source": [
    "### INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0905faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the email column as index for this dataframe\n",
    "# this only sets the index temporiraly.\n",
    "# to set permanently\n",
    "dict_df.set_index(\"email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b21125",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.set_index(\"email\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have selected an index we can use them instead of the numerical default indexes like 0,1,2 ect when using loc\n",
    "dict_df.set_index(\"email\").loc[\"JaneDoe@email.com\", \"first\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "daa303d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you set and index and mistakinly mutate the dataframe using inplace you can reset the index\n",
    "dict_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246628ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index can also be set while creating the dataframe\n",
    "\n",
    "# to normaalize missing values that are not the normal missing values of np.na or None create a list of those custom values\n",
    "# pass this list into the read_csv with argument na_values\n",
    "custom_na_values=[\"NA\", \"Missing\"]\n",
    "indexed_df = pd.read_csv(ROOT_DIR / \"data\" / \"stackoverflow_survey\" / \"2019\" / \"survey_results_public.csv\", index_col=\"Respondent\", na_values=custom_na_values)\n",
    "\n",
    "indexed_schema_df = pd.read_csv(ROOT_DIR / \"data\" / \"stackoverflow_survey\" / \"2019\" / \"survey_results_schema.csv\", index_col=\"Column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d168fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c390790",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f00419",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_schema_df.loc[\"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3995c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_schema_df.loc[\"MgrIdiot\", \"QuestionText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09920ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the index\n",
    "indexed_schema_df.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102448d",
   "metadata": {},
   "source": [
    "### FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e38334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter mask. \n",
    "# This creates a seris of booleans we can pass to a dataframe df OR df.loc\n",
    "dict_df[\"last\"] == \"Doe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "526d286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_mask = (dict_df[\"last\"] == \"Doe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply filter mask to dataframe to get back rows that match the filter\n",
    "dict_df[filter_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also put the filter mask directly in the dataframe call.  This looks untidy\n",
    "dict_df[(dict_df[\"last\"]==\"Doe\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d217776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering by .loc is also a way to achieve the same results.\n",
    "dict_df.loc[filter_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .loc allows us to additionally select out the columns we need by passing a second argument as usual to .loc\n",
    "dict_df.loc[filter_mask, \"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27336b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND operator (&)\n",
    "filter_mask_2=((dict_df[\"last\"]==\"Doe\") & (dict_df[\"first\"] == \"John\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.loc[filter_mask_2, \"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1210d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR operator (|)\n",
    "filter_mask_3 = ((dict_df[\"last\"] == \"Schafer\") | (dict_df[\"first\"] == \"John\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[filter_mask_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe60bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT operator (~)\n",
    "filter_mask_4 = ~((dict_df[\"last\"] == \"Schafer\") | (dict_df[\"first\"] == \"John\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[filter_mask_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do negation in dataframe call as an alternative\n",
    "filter_mask_5 = ((dict_df[\"last\"] == \"Schafer\") | (dict_df[\"first\"] == \"John\"))\n",
    "dict_df[~filter_mask_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7624e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_salary = (indexed_df[\"ConvertedComp\"] > 70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.loc[high_salary, [\"Country\", \"LanguageWorkedWith\",\"ConvertedComp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eab2622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want to filter down this list to a few selected countries\n",
    "countries = [\"United States\", \"India\", \"United Kingdom\", \"Germany\", \"Canada\"]\n",
    "filter_mask_6 = indexed_df[\"Country\"].isin(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.loc[filter_mask_6, \"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b41ad924",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_mask_7 = indexed_df[\"LanguageWorkedWith\"].str.contains(\"Python\", na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161dddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.loc[filter_mask_7,\"LanguageWorkedWith\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec84d3",
   "metadata": {},
   "source": [
    "### UPDATING ROWS AND COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8071c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column headings\n",
    "dict_df.columns=[\"first_name\", \"last_name\", \"email\"]\n",
    "dict_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92268bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e390f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all column names to uppercase using a list comprehension\n",
    "dict_df.columns = [x.lower() for x in dict_df.columns]\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces with underscores in column name\n",
    "dict_df.columns = [x.replace(\" \", \"_\") for x in dict_df.columns]\n",
    "# OR\n",
    "dict_df.columns = dict_df.columns.str.replace(\" \", \"_\")\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a309ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change only some columns not all, using the rename method.\n",
    "# it takes a column parameter which is just a dict of the columns we want to affect\n",
    "# note this creates a new dataframe and the change made is not in place. So need to resave it to a variable\n",
    "dict_df = dict_df.rename(columns={\"first_name\":\"first\", \"last_name\":\"last\"})\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing values in the dataframe for entire row\n",
    "# select row\n",
    "# pass in all new values you want to change in that row\n",
    "dict_df.loc[2] = [\"John\", \"Smith\", \"JohnSmith@email.com\"]\n",
    "dict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing values in the dataframe for specific columns in a row\n",
    "# select row\n",
    "# pass in all new values you want to change in that row\n",
    "dict_df.loc[2, [\"last\", \"email\"]] = [\"Doe\", \"JohnDoe@email.com\"]\n",
    "dict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change a single value\n",
    "# select row and col  and change the value in it\n",
    "dict_df.loc[2, \"last\"] = \"Smith\"\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS use .loc when setting values or you can run into errors\n",
    "filter_mask_8 = (dict_df[\"email\"]==\"JohnDoe@email.com\")\n",
    "\n",
    "# .loc is use to apply the filter to the rows and the second arg selects the desired column\n",
    "dict_df.loc[filter_mask_8,\"last\"] = \"Smith\"\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e61f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all emails to lowercase\n",
    "dict_df[\"email\"] = dict_df[\"email\"].str.lower()\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 other methods to do updates\n",
    "# apply\n",
    "# map\n",
    "# replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply\n",
    "# works on a dataframe or series\n",
    "# behaviour is different depending on if it operates on a dataframe or a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150da8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on a series\n",
    "# apply a function to every value in our series\n",
    "\n",
    "# applies the len function to all values in our series\n",
    "dict_df[\"email\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_email(email:str)->str:\n",
    "    return email.upper()\n",
    "\n",
    "dict_df[\"email\"] = dict_df[\"email\"].apply(update_email)\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a lambda function is also possible\n",
    "dict_df[\"email\"] = dict_df[\"email\"].apply(lambda x: x.lower())\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f778689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on a dataframe\n",
    "# apply a function to every series of the data frame\n",
    "# therefore only use functions that can be used properly with series\n",
    "\n",
    "# applies the len function to the series in the dataframe\n",
    "# eg each series in dict_df is 3 units long\n",
    "# i.e the series contains 3 values\n",
    "dict_df.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the minimum value from each column\n",
    "dict_df.apply(pd.Series.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29eb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a lamda\n",
    "dict_df.apply(lambda x: x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map (dataframe)\n",
    "# it wokrs on dataframes and series\n",
    "# it will run the function on every value in the dataframe\n",
    "\n",
    "dict_df.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "dict_df.map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd469a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map (series)\n",
    "dict_df[\"first\"].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful if a value in the series is not in your map then it will be converted to a NaN\n",
    "# use replace instead!!!!\n",
    "dict_df[\"first\"].map({\"Corey\": \"Chris\", \"Jane\":\"Mary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e67e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[\"first\"].replace({\"Corey\": \"Chris\", \"Jane\":\"Mary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "22b06a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# praticing what we learned in Stackoverflow data\n",
    "\n",
    "indexed_df= indexed_df.rename(columns={\"ConvertedComp\":\"SalaryUSD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b01024",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[\"SalaryUSD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[\"Hobbyist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d45129",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[\"Hobbyist\"].map({\"Yes\":True, \"No\":False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870c51c",
   "metadata": {},
   "source": [
    "### ADDING AND REMOVING ROWS AND COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3097324",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[\"first\"] + \" \" + dict_df[\"last\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ca78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column \"full_name\" from two existing columns\n",
    "# by combining two existing columns to get a series and assinging that as a new column to the dataframe\n",
    "dict_df[\"full_name\"] = dict_df[\"first\"] + \" \" + dict_df[\"last\"]\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ef7f5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove column\n",
    "dict_df= dict_df.drop(columns=[\"first\", \"last\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d04f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1\n",
       "0  Corey  Schafer\n",
       "1   Jane      Doe\n",
       "2   John    Smith"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split would create a series where each value is a list eg [\"Tom\", Hanks]\n",
    "# to brek that into columns per items in list, use the \"expand\" flag\n",
    "dict_df[\"full_name\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e666bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[[\"first\", \"last\"]] = dict_df[\"full_name\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7826720",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ad3f139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a single row\n",
    "new_row = pd.DataFrame({\"first\": [\"Tony\"]})\n",
    "dict_df=pd.concat([dict_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d52fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2bce7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add multiple rows\n",
    "\n",
    "people_2 = {\n",
    "    \"first\":[\"Tony\", \"Steve\"],\n",
    "    \"last\": [\"Stark\", \"Rogers\"],\n",
    "    \"email\": [\"Ironman@avengers.com\",\"Cap@avengers.com\"],\n",
    "}\n",
    "\n",
    "new_rows = pd.DataFrame(people_2)\n",
    "dict_df = pd.concat([dict_df, new_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a row\n",
    "dict_df.drop(index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove multiple rows based on a filter\n",
    "filt = dict_df[\"last\"]==\"Doe\"\n",
    "dict_df.drop(index=dict_df[filt].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426b375",
   "metadata": {},
   "source": [
    "### SORTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9212542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.loc[2,\"last\"] = \"Doe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.sort_values(by=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1761a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort descinding\n",
    "dict_df.sort_values(by=\"last\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by multiple columns\n",
    "dict_df.sort_values(by=[\"last\", \"first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae11d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell each column how to be sorted by passing a list of matching true, false values to the ascending pararmeter\n",
    "dict_df.sort_values(by=[\"last\", \"first\"], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by index\n",
    "dict_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da401061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and display only the sorted column\n",
    "dict_df[\"last\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6d6c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with the StackOverflow survey data\n",
    "indexed_df = indexed_df.sort_values(by=[\"Country\", \"SalaryUSD\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe217452",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[[\"Country\", \"SalaryUSD\"]].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 10 highest salaries\n",
    "indexed_df[\"SalaryUSD\"].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d27664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View ten largest salaries but with additional data\n",
    "indexed_df.nlargest(10, \"SalaryUSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cbec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.nsmallest(10, \"SalaryUSD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf3f49",
   "metadata": {},
   "source": [
    "### Grouping AND AGGREGATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca924ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get median salary\n",
    "indexed_df[\"SalaryUSD\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39172e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a broad overview (stats) of our dataframe\n",
    "indexed_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[\"SalaryUSD\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b59d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts non-missing rows\n",
    "indexed_df[\"SalaryUSD\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of each distinct value in the series\n",
    "indexed_df[\"Hobbyist\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get breakdown of social media platforms used\n",
    "indexed_df[\"SocialMedia\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd13d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get breakdown of social media platforms used by percentile\n",
    "indexed_df[\"SocialMedia\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping consist of:\n",
    "# 1. Split the object\n",
    "# 2. Apply a function\n",
    "# 3. Combine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5816113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces a DataFrameGroupBy object\n",
    "# it is an object that contains a bunch of groups\n",
    "country_groups=indexed_df.groupby([\"Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a tuple or a list is passed to get_group\n",
    "# NOTE if the tuple conatains just one value much end it with a trailing comma to ensure its a tuple\n",
    "country_groups.get_group((\"India\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcf80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country (SPLIT)\n",
    "country_groups = indexed_df.groupby([\"Country\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039770f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of social media platforms per country (APPLY FUNCTION)\n",
    "country_groups[\"SocialMedia\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of social media platforms for India\n",
    "country_groups[\"SocialMedia\"].value_counts().loc[\"Russian Federation\"]\n",
    "\n",
    "# NOTE you can get same result BUT ONLY for one country using filter\n",
    "# filt = indexed_df[\"Country\"] == \"India\"\n",
    "# indexed_df.loc[filt][\"SocialMedia\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median salary by country\n",
    "country_groups[\"SalaryUSD\"].median().loc[\"Germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcee3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple functions on your gruop using AGG\n",
    "country_groups[\"SalaryUSD\"].agg([\"median\", \"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple functions on your gruop using AGG, drill down to a specific country\n",
    "country_groups[\"SalaryUSD\"].agg([\"median\", \"mean\"]).loc[\"Canada\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people in each country use python. USE FILTER\n",
    "filt = indexed_df[\"Country\"] == \"India\"\n",
    "\n",
    "# sum takes the series of true, flase and treats True as 1 and false as 0. So it can indeed sum up a boolean column\n",
    "indexed_df.loc[filt][\"LanguageWorkedWith\"].str.contains(\"Python\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f346b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people in each country use python. USE AGGREGATION\n",
    "# we apply a function to each series in this group. NOTE the function RuNS on the series\n",
    "# as usual each series is made up of the data for a country\n",
    "country_groups[\"LanguageWorkedWith\"].apply(lambda x: x.str.contains(\"Python\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30247c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now instead of display numbers per country display percentages which is more useful\n",
    "\n",
    "# 1. Get the # of respondants per country\n",
    "respondants_by_country = indexed_df[\"Country\"].value_counts()\n",
    "\n",
    "# 2. Get the # of respondants per country that use python\n",
    "respondants_by_country_python =country_groups[\"LanguageWorkedWith\"].apply(lambda x: x.str.contains(\"Python\").sum())\n",
    "\n",
    "\n",
    "# merge the two series columnwise using pd.concat\n",
    "respondants_by_country_python_percent = pd.concat([respondants_by_country, respondants_by_country_python], axis=\"columns\")\n",
    "\n",
    "# give colums proper names\n",
    "respondants_by_country_python_percent= respondants_by_country_python_percent.rename(columns={\"count\": \"NumRespondants\", \"LanguageWorkedWith\":\"NumKnowsPython\"})\n",
    "\n",
    "# Create a new column that will now hold percentages\n",
    "respondants_by_country_python_percent[\"PctKnowsPython\"] = (respondants_by_country_python_percent[\"NumKnowsPython\"] / respondants_by_country_python_percent[\"NumRespondants\"]) * 100\n",
    "\n",
    "respondants_by_country_python_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "respondants_by_country_python_percent=respondants_by_country_python_percent.sort_values([\"PctKnowsPython\"], ascending=False)\n",
    "respondants_by_country_python_percent.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "respondants_by_country_python_percent.loc[\"Japan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2140e",
   "metadata": {},
   "source": [
    "### CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16039eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_dict = {\n",
    "    \"first\": [\"Corey\", \"Jane\", \"John\", \"Chris\", np.nan, None, \"NA\"],\n",
    "    \"last\": [\"Schafer\", \"Doe\", \"Doe\", \"Schafer\", np.nan, np.nan, \"Missing\"],\n",
    "    \"email\": [\"CoreyMSchafer@gmail.com\", \"JaneDoe@email.com\", \"JohnDoe@email.com\", None, np.nan, \"Anonymous@email.com\", \"NA\"],\n",
    "    \"age\": [\"33\", \"55\", \"63\", \"36\", None, None, \"Missing\"],\n",
    "}\n",
    "\n",
    "cleaning_df = pd.DataFrame(cleaning_dict)\n",
    "\n",
    "# Replace missing data marked with custom representation with real missing data\n",
    "# for example the creator of the data may use \"NA\" or \"Missing\" to represent missing data\n",
    "# we just need to replace those in entire dataframe with real repesentation of missing data\n",
    "cleaning_df= cleaning_df.replace(\"NA\", np.nan)\n",
    "cleaning_df= cleaning_df.replace(\"Missing\", np.nan)\n",
    "\n",
    "# NOTE for csv files we handle custom representations of missing data differently!!!\n",
    "# See cell far above where we import to indexed_df\n",
    "\n",
    "cleaning_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cce9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing data\n",
    "cleaning_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults with which dropna runs\n",
    "# axis (index, columns)\n",
    "#  - index: drop na values when our rows are missing values\n",
    "#  - columns: drop na values when our columns are missing values\n",
    "#\n",
    "# how (any, all) - criteria for dropping\n",
    "#  - any: drop when some values are missing\n",
    "#  - all: drop when all values are missing\n",
    "\n",
    "# dropping rows, since axis is index, where some values are missing across the row\n",
    "cleaning_df.dropna(axis=\"index\", how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffae3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows, since axis is index, where all values are missing across the row\n",
    "cleaning_df.dropna(axis=\"index\", how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns, since axis is columns, where all values are missing in the column\n",
    "cleaning_df.dropna(axis=\"columns\", how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop rows that have missing values in specific columns by passing a \"subset\" argument to dropna\n",
    "cleaning_df.dropna(axis=\"index\", how=\"any\", subset=[\"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ed95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if both last and email are missing\n",
    "cleaning_df.dropna(axis=\"index\", how=\"all\", subset=[\"last\", \"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which values in our df are identified as missing data\n",
    "# missing data will have true \n",
    "cleaning_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ea8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing data with a default value.\n",
    "# example when working with numeric data may want to fill missing data with zeros eg. cleaning_df.fillna(0)\n",
    "\n",
    "# here we do not have numerical data so we will fill missing data with the string 'MISSING'\n",
    "cleaning_df.fillna(\"MISSING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the age field looks like they are numeric but they are actually strings\n",
    "cleaning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types of each column\n",
    "cleaning_df.dtypes\n",
    "\n",
    "# as you can see the age datatype is not a numeric so doing numerical operations on it will fail\n",
    "# we will need to convert this column to a numeric datatype\n",
    "# now if this column contains missing data, will need to convert to FLOAT (not int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19665acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert or cast this column to a float datatype\n",
    "# remember to use float not int as if missing data is present usually represented by np.nan, that is a float under the hood\n",
    "# and it would be an issue trying to cast those as an int\n",
    "cleaning_df[\"age\"] = cleaning_df[\"age\"].astype(float)\n",
    "cleaning_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e602064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can calulate the mean aga\n",
    "cleaning_df[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c51a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average number of years coding among participants of the Stack Overflow survey\n",
    "\n",
    "indexed_df[\"YearsCode\"].head(10)\n",
    "\n",
    "# Note that the dtype is object, so need to convert it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dc906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to float\n",
    "indexed_df[\"YearsCode\"]=indexed_df[\"YearsCode\"].astype(float)\n",
    "\n",
    "# this will still give an error though as some of the values in this coulumn are actual strings\n",
    "# example one such value is \"Less than 1 year\". Whoaaa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0974534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets look at the unique values of this column to see what we are dealing with\n",
    "indexed_df[\"YearsCode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad45f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see we have two problematic strings\n",
    "# \"More than 50 years\" --> we will replace this with 51. meh!\n",
    "# \"Less than 1 year\"  --> we will replace this with 0\n",
    "\n",
    "indexed_df[\"YearsCode\"] = indexed_df[\"YearsCode\"].replace(\"Less than 1 year\", 0)\n",
    "indexed_df[\"YearsCode\"] = indexed_df[\"YearsCode\"].replace(\"More than 50 years\", 51)\n",
    "\n",
    "indexed_df[\"YearsCode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f854ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW we can try conversion of this column to float again\n",
    "indexed_df[\"YearsCode\"]=indexed_df[\"YearsCode\"].astype(float)\n",
    "\n",
    "# Now we can get the mean/average\n",
    "indexed_df[\"YearsCode\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81103302",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df[\"YearsCode\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf56ca",
   "metadata": {},
   "source": [
    "### DATE AND TIME SERIES DATA\n",
    "\n",
    "#### Resources\n",
    "- [Datetime Formatting Codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)\n",
    "- [Pandas Date Offset Codes](ttps://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "81350917",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df =  pd.read_csv(ROOT_DIR / \"data\" / \"ETH_1h.csv\")\n",
    "\n",
    "# Alternative to convert date/time columns on load\n",
    "datetime_df =  pd.read_csv(ROOT_DIR / \"data\" / \"ETH_1h.csv\", parse_dates=[\"Date\"], date_format=\"%Y-%m-%d %I-%p\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bdfc8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column does not follow a standardize date format, we must past it a format string to help it out, otherwise will get error\n",
    "datetime_df[\"Date\"] = pd.to_datetime(datetime_df[\"Date\"], format=\"%Y-%m-%d %I-%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2cd3ecd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friday'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_df.loc[0,\"Date\"].day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run functions on entire series by using \".dt\"\n",
    "datetime_df[\"Date\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "37a79f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a day name column\n",
    "datetime_df[\"DayOfWeek\"] = datetime_df[\"Date\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get earliest date\n",
    "datetime_df[\"Date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can subtract dates to get time between dates. This is called a time delta\n",
    "\n",
    "# find the time between the earliest and latest date\n",
    "\n",
    "datetime_df[\"Date\"].max() - datetime_df[\"Date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by date\n",
    "\n",
    "filt = (datetime_df[\"Date\"] >= \"2019\") & (datetime_df[\"Date\"] < \"2020\")\n",
    "datetime_df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec291c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by date\n",
    "\n",
    "filt = (datetime_df[\"Date\"] >= pd.to_datetime(\"2019-01-01\")) & (datetime_df[\"Date\"] < pd.to_datetime(\"2020-01-01\"))\n",
    "datetime_df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b19369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing using dates\n",
    "# must set index to the Date column as each of its values are actually unique.  Then we can slice\n",
    "\n",
    "datetime_df= datetime_df.set_index(\"Date\").sort_index()\n",
    "\n",
    "datetime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can slice\n",
    "datetime_df.loc[\"2017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df.loc[\"2020-01\":\"2020-02\"]\n",
    "datetime_df.loc[\"2020-01\":\"2020-02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "c9e9dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(195.1655902777778)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the avg Close amt for a date range\n",
    "datetime_df.loc[\"2020-01\":\"2020-02\"][\"Close\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "712e98c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(132.68)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_df.loc[\"2020-01-01\"][\"High\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ccea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get high value by day using resample, because the data is high per hour per day\n",
    "# currently it is sampled per hour\n",
    "# we can resample per day by passing \"D\" to \"resample\" or \"2D\" for every 2 days,  \"W\" for week.\n",
    "# Now tell it what function you want to apply to the resampling\n",
    "daily_highs= datetime_df[\"High\"].resample(\"D\").max()\n",
    "\n",
    "daily_highs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "3b9fae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(132.68)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_highs.loc[\"2020-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b49fd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455951dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_highs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling multipe columns\n",
    "datetime_df.resample(\"W\").agg({\"High\":\"max\", \"Low\":\"min\", \"Close\": \"mean\", \"Volume\":\"sum\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
